<!-- <!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Optimizing Training Strategies for EMG-Controlled Prostheses</title>
        <link rel="stylesheet" href="../assets/css/style.css">
    </head>
    <body>
        <header class="site-header">
            <div class="wrap header-inner">
                <nav class="site-nav">
                    <a href="./">Home</a>
                    <a href="../about.html">About</a>
                    <a href="../projects.html">Projects</a>
                    <a href="../contact.html">Contact</a>
                </nav>
            </div>
        </header>

        <div class="container">
            <div class="hero">
                <h1>Optimizing Training Strategies for EMG-Controlled Prostheses</h1>
                <p class="tagline">A PhD project turned into a data analysis case study.</p>
                <div class="hero-links">
                    <a href="https://github.com/vayneeS/prosthesis-strategies-with-ml" target="_blank">View Code on GitHub</a>
                </div>
            </div>

            <div class="content">
                <div class="story-section" id="overview">
                    <h2>Project Overview</h2>
                    <p>
                        One of the problems faced by prosthesis users is the lack of control of their device over time. Controlling an upper-limb prosthesis means learning how muscle signals (EMG) are translated into
                        actions by a machine-learning classifier. Training strategies directly affect how quickly and how
                        well users acquire this control.
                    </p>
                    <p>
                        In this project, I analyzed EMG data from users performing gesture training under different strategies
                        to answer a simple product question: <strong>how should we structure training so that people learn
                        faster and control the device more reliably?</strong>. The strategy I developed is adaptive, which means
                        that it tailors the training sequence based on each user's performance.
                    </p>
                    <p>This case study reframes my PhD work as an end-to-end data analysis project, showcasing how I:</p>
                    <ul>
                        <li>Work with noisy biosignals</li>
                        <li>Define clear metrics for learning</li>
                        <li>Compare training strategies</li>
                        <li>Extract product-ready insights and recommendations</li>
                    </ul>
                </div>

                <div class="story-section" id="skills">
                    <h2>This Project Demonstrates</h2>
                    <ul>
                        <li>Working with <strong>noisy time-series biosignals</strong> and applying appropriate smoothing</li>
                        <li>Designing <strong>interpretable metrics</strong> for learning and user understanding</li>
                        <li>Building a <strong>structured analysis pipeline</strong> from raw data to visual summaries</li>
                        <li>Comparing training strategies using <strong>clear visual and statistical evidence</strong></li>
                        <li>Translating complex experimental results into <strong>product-ready insights</strong></li>
                        <li>Thinking in terms of <strong>user experience, onboarding, and long-term engagement</strong></li>
                        <li>Communicating findings in a way that is accessible to <strong>data leads, clinicians, and product managers</strong></li>
                    </ul>
                </div>

                <div class="story-section" id="business-questions">
                    <h2>Business Questions</h2>
                    <p>
                        Reframed from the original research aims, the analysis focused on three core business questions:
                    </p>

                    <div class="highlight-box">
                        <h4>2. Does an adaptive training strategy improve the classifier's performance during training?</h4>
                        <p>
                            I treat trial-level classification accuracy as a proxy for quality of EMG control and skill
                            acquisition, and compare it across strategies.
                        </p>
                    </div>

                    <div class="highlight-box">
                        <h4>1. Can adaptive training help users reach accurate prosthesis control faster?</h4>
                        <p>
                            Here, I compare how quickly users improve classification accuracy under different training
                            strategies. This reflects learning speed and onboarding efficiency.
                        </p>
                    </div>

                    <div class="highlight-box">
                        <h4>3. Does adaptive training strengthen the user's mental model of how the prosthesis interprets their movements?</h4>
                        <p>
                            I evaluate user performance on post-training functional tests to assess whether they have a
                            more accurate intuition of how the ML model responds to their gestures.
                        </p>
                    </div>

                    <p>
                        These questions could translate into product concerns such as <strong>reducing time to competency,
                        improving user experience, and increasing long-term confidence in the device</strong>.
                    </p>
                </div>

                <div class="story-section" id="data-metrics">
                    <h2>Data collection and Key Metrics</h2>
                    <p>
                        The dataset comes from EMG-based training sessions which I led, where users practiced hand and wrist gestures
                        with different training strategies. The goal was to see how these strategies affected learning and control.
                        I used a Myo armband to collect multichannel EMG data as users trained a machine-learning classifier to recognize their gestures.
                        The Myo device streams EMG signals from 8 sensors placed around the forearm, capturing muscle activity during gesture attempts.
                    </p>

                    <figure>
                        <img src="../images/experiment.png" alt="Myo armband setup for EMG data collection" class="responsive-img">
                        <figcaption>
                            The Myo armband is placed on the user's forearm for EMG data collection during prosthesis training sessions.
                            Users performed a series of hand and wrist gestures while the device recorded multichannel EMG signals.
                            A robotic prosthesis provided real-time feedback based on the classifier's predictions.
                        </figcaption>
                    </figure>

                    <h2>Data Overview</h2>
                    <table class="portfolio-table">
                        <thead>
                            <tr>
                                <th>Column</th>
                                <th>Type</th>
                                <th>Description</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>pid</strong></td>
                                <td>Integer</td>
                                <td>Participant ID. Identifies which user the EMG sample comes from.</td>
                            </tr>
                            <tr>
                                <td><strong>cond</strong></td>
                                <td>String</td>
                                <td>Training condition used during data collection.</td>
                            </tr>
                            <tr>
                                <td><strong>trial</strong></td>
                                <td>Integer</td>
                                <td>Order index of the movement during training.</td>
                            </tr>
                            <tr>
                                <td><strong>x</strong></td>
                                <td>List of floats</td>
                                <td>RMS features extracted from the EMG window (one per channel).</td>
                            </tr>
                            <tr>
                                <td><strong>y</strong></td>
                                <td>String</td>
                                <td>Gesture label corresponding to the window.</td>
                            </tr>
                        </tbody>
                    </table>

                    <div class="data-list">
                        <h4>Data Sources:</h4>
                        <ul>
                            <li>Multichannel EMG signals from a Myo armband (8 channels)</li>
                            <li>120 training trials per participant</li>
                            <li>3 prosthesis training strategies:
                                <ul>
                                    <li><strong>Random Curriculum (RC).</strong> The gestures are presented in a random order without any specific selection criteria.</li>
                                    <li><strong>User-Choice Curriculum (UCC).</strong> The user selects gestures based on their preference or perceived difficulty.</li>
                                    <li><strong>Gesture Separability Curriculum (GSC).</strong> This is the adaptive curriculum, which selects the most informative gestures based on separability metrics.</li>
                                </ul>
                            </li>
                        </ul>
                    </div>

                    <div class="data-list">
                        <h4>Key Metrics:</h4>
                        <ul>
                            <li><strong>Learning speed</strong>
                                <ul>
                                    <li>Evolution of classification accuracy over 120 trials.
                                        Accuracy corresponds to the proportion of correctly classified signal windows within each trial.
                                        After the training phase, a post-test was performed to generate an independent test set, which was then used to evaluate model accuracy throughout the training process.</li>
                                    <li>Learning rate per strategy.
                                        Learning curves often follow a power-law, expressed as <span><strong>log(Performance) = log(k) + Î± log(Number of trials)</strong></span>.
                                        Linear regression on learning data transforms the learning function into a straight line, which can be analyzed. The slope gives the learning rate; a steeper positive slope â†’ faster improvement in performance.</li>
                                </ul>
                            </li>
                            <li><strong>User understanding / mental model</strong>
                                <ul>
                                    <li>Accuracy obtained on post-training functional tests</li>
                                    <li>Reflects how well users understand how the prosthesis interprets their movements</li>
                                </ul>
                            </li>
                        </ul>
                    </div>

                    <p>
                        These metrics provide an analytical link between the accuracy of the signal classification, user learning, and
                        product experience.
                    </p>
                </div>

                <div class="story-section">
                    <p>
                        My analysis and machine learning pipeline relied on a set of core Python libraries:
                    </p>
                    <ul class="tech-list">
                        <li>
                            <strong>Data preprocessing:</strong>
                            <span class="tech-name">NumPy</span> and
                            <span class="tech-name">pandas</span> for numerical operations and structured data handling.
                        </li>
                        <li>
                            <strong>Statistical analysis:</strong>
                            <span class="tech-name">SciPy</span> for basic statistics and
                            <span class="tech-name">statsmodels</span> for more advanced tests such as ANOVAs.
                        </li>
                        <li>
                            <strong>Machine learning:</strong>
                            <span class="tech-name">scikit-learn</span> to build a classification pipeline using
                            <em>StandardScaler</em> and <em>LinearDiscriminantAnalysis</em> for predicting EMG-based movement classes.
                            <p>
                                LDA works well for prosthesis classification because it is fast, interpretable, and performs reliably even with noisy or limited EMG data.
                                Its strength lies in how it maximizes class separability: it finds a projection where signals from different movements are pushed as far apart as possible while each movement remains internally compact.
                                This makes LDA both efficient and robust for real-time control systems. The adaptive training strategy (GSC) specifically leverages this property by selecting gestures that are less separable, thereby focusing user practice on the most challenging distinctions.
                            </p>
                        </li>
                        <li>
                            <strong>Performance evaluation:</strong>
                            confusion matrices to inspect per-class accuracy and understand how the model performs across gestures.
                        </li>
                        <li>
                            <strong>Visualization:</strong>
                            <span class="tech-name">Matplotlib</span> and
                            <span class="tech-name">Seaborn</span> to create learning curves and summary bar plots.
                        </li>
                    </ul>
                </div>

                <div class="methodology" id="methodology">
                    <h3>Methodology: From Noisy EMG to Learning Curves</h3>
                    <p>
                        Even with a relatively small dataset, EMG signals are inherently noisy. I applied focused,
                        realistic preprocessing steps:
                    </p>

                    <h4>Root Mean Square (RMS) smoothing of EMG channels</h4>
                    <ul>
                        <li>Applied Root Mean Square (RMS) smoothing to each channel</li>
                        <li>Reduced high-frequency noise and stabilized signal envelopes</li>
                        <li>Prepared the data for robust classification and feature extraction</li>
                    </ul>

                    <figure>
                        <img src="../images/rms.png" alt="Root Mean Square (RMS) smoothing snippet" class="responsive-img">
                        <figcaption>
                            Root Mean Square (RMS) smoothing.
                        </figcaption>
                    </figure>

                    <h4>Participant-level outlier removal</h4>
                    <ul>
                        <li>Identified participants with extreme average accuracy values (e.g. >3 standard deviations from the group)</li>
                        <li>Removed these outliers to avoid distorted group-level trends</li>
                        <li><strong>Result:</strong> cleaner learning curves and more reliable comparisons between strategies</li>
                    </ul>

                    <figure>
                        <img src="../images/remove_outliers.png" alt="Remove outliers snippet" class="responsive-img">
                        <figcaption>
                            Example of participant-level outlier removal.
                        </figcaption>
                    </figure>

                    <h4>Trial-level aggregation of accuracy</h4>
                    <ul>
                        <li>Aggregated window-level classifier predictions into a single accuracy score per trial</li>
                        <li>Enabled consistent tracking of performance for each user across 120 trials</li>
                    </ul>

                    <p style="margin-top: 20px;"><strong>The analysis pipeline then followed this structure:</strong></p>
                    <ol>
                        <li>Apply RMS smoothing to EMG streams</li>
                        <li>Extract features- RMS is itself an amplitude-based feature, normalize using the StandardScaler, and classify EMG windows</li>
                        <li>Aggregate predictions into trial-level accuracy</li>
                        <li>Plot learning curves for each strategy</li>
                        <li>Compute learning rate of the classifier</li>
                        <li>Compare post-training functional outcomes to assess mental models</li>
                    </ol>
                </div>

                <div class="story-section" id="visual-analysis">
                    <h2>Visual Analysis</h2>

                    <h3>Learning Curves</h3>
                    <figure>
                        <img src="../images/accuracy_across_trials_by_strategy.png" alt="Learning curves showing classification accuracy over 120 trials" class="responsive-img">
                        <figcaption>
                            Learning curves showing classification accuracy over 120 trials for each training strategy.
                            The adaptive strategy displays a slower early increase compared to other strategies and seems to reach a plateau near the end of training.
                            The differences in final accuracy across strategies are not significant, meaning that there is no evidence that they are similar.
                        </figcaption>
                    </figure>

                    <h3>Learning rates</h3>
                    <figure>
                        <img src="../images/Learning_rates_by_strategy.png" alt="Learning rates across strategies" class="responsive-img">
                        <figcaption>
                            Learning rates derived from log-log transformed accuracy data. The adaptive strategy (GSC)
                            shows a significantly higher learning rate, indicating that users improve their control
                            skills more rapidly compared to other strategies. Absolute values of learning rates are shown on the bars.
                        </figcaption>
                    </figure>

                    <h3>Functional Performance / Mental Model</h3>
                    <figure>
                        <img src="../images/TPR_comparison.png" alt="Post-training functional accuracy comparison" class="responsive-img">
                        <figcaption>
                            Post-training functional accuracy for each strategy. Users trained with the adaptive strategy
                            perform better on test tasks that require anticipating how the classifier responds to their gestures,
                            reflecting a stronger mental model of the system.
                        </figcaption>
                    </figure>
                </div>
                <div class="story-section" id="statistical-analysis">
                    <h2>Statistical Analysis</h2>
                    <p>
                        To validate the visual findings, I use ANOVAs and t-tests when data were normally distributed, and Kruskalâ€“Wallis otherwise.
                        Significant results are reported using p-values, along with effect sizes to indicate the magnitude of the differences.
                    </p>
                    <ul>
                        <li>
                            <strong>Learning Rates:</strong>
                            ANOVA shows a significant effect of strategy on learning rate (p &lt 0.001).
                            Post-hoc tests confirms that the adaptive strategy (GSC) has a significantly higher learning rate than both RC and UCC.
                        </li>
                        <li>
                            <strong>Post-Training Functional Accuracy:</strong>
                            Kruskalâ€“Wallis shows a significant effect of strategy (p = 0.03).
                            Post-hoc tests shows that GSC outperformed UCC (p &lt 0.04).
                        </li>
                    </ul>

                </div>
                <div class="story-section" id="insights">
                    <h2>Insights & Recommendations</h2>

                    <div class="finding-card">
                        <h4>ðŸš€ Insight 1 â€“ Adaptive training accelerates learning</h4>
                        <p>
                            <strong>Insight:</strong> Users trained with the adaptive strategy (GSC) improved their classification
                            accuracy significantly faster (x% increase, p < 0.05, effect-size = ) than other groups. Learning curves
                            show steeper improvement and earlier stabilization, indicating more efficient learning dynamics.
                        </p>
                        <p>
                            <strong>Recommendation:</strong> Integrate performance-based adaptive curriculum into the prosthesis
                            training workflow. Automatically selecting the next gesture based on user performance can shorten
                            onboarding time, reduce trial-and-error frustration, and make early sessions more rewarding for
                            new users.
                        </p>
                    </div>

                    <div class="finding-card">
                        <h4>ðŸŽ¯ Insight 2 â€“ Adaptive training leads to stronger gains in performance</h4>
                        <p>
                            <strong>Insight:</strong> By the end of training, users trained with the adaptive strategy (GSC) achieved both a
                            larger increase in accuracy (x% increase, p < 0.05, effect-size = ) compared to other groups. With final accuracies which converge for all strategies,
                            adaptive training appears to help users learn faster. This could lead to more reliable control in the long run.
                        </p>
                        <p>
                            <strong>Recommendation:</strong> Make adaptive training the default path for new prosthesis users,
                            while keeping random or fixed curricula only as backup options. This can reduce the number of
                            sessions required to reach clinical competency and lower the support load for clinicians or
                            product specialists.
                        </p>
                    </div>

                    <div class="finding-card">
                        <h4>ðŸ§  Insight 3 â€“ Adaptive training strengthens user mental models</h4>
                        <p>
                            <strong>Insight:</strong> Users trained with the adaptive strategy performed better (x% , p < 0.05, effect-size = ) on post-training
                            functional tests, indicating a deeper understanding or intuition of how the prosthesis interprets their muscle
                            signals.
                        </p>
                        <p>
                            <strong>Recommendation:</strong> Strengthen the intuition by combining adaptive training with simple in-app feedback that explains
                            why specific gestures are selected or repeated. Surfacing this logic helps users form accurate
                            expectations of the device, improving long-term trust, adherence, and overall user satisfaction.
                        </p>
                    </div>
                </div>

                <div class="impact-statement" id="impact">
                    <h3>Next Steps</h3>
                    <p>
                        This analysis shows that a relatively simple adaptive strategy, combined with basic signal preprocessing
                        (RMS smoothing) and targeted outlier removal, can improve how users learn to control a
                        machine-learning-driven device.
                    </p>
                    <p style="margin-top: 15px;">
                        For product teams working on prosthetics, rehabilitation tools, gaming, or any human-in-the-loop ML
                        system, structuring training around user performance is a powerful lever
                        for better onboarding, stronger skills, and more confident long-term use.
                    </p>
                </div>

                <!-- 9. SKILLS DEMONSTRATED -->

<!-- 10. REPOSITORY LINK -->
<!-- <div class="story-section" id="repo">
                    <h2>Code and Reproducibility</h2>
                    <p>
                        The full code, preprocessing scripts, and analysis notebooks for this project are available here:
                    </p>
                    <a href="https://github.com/vayneeS/prosthesis-strategies-with-ml" target="_blank" class="repo-link">
                        ðŸ“‚ View GitHub Repository
                    </a>
                </div> -->
<!-- <div class="story-section" id="repo">
                    <p>
                        Reference:
                        <a href="https://amu.hal.science/ISIR_ACIDE/hal-04527854v1" target="_blank">
                            Comparing Teaching Strategies of a Machine Learning-based Prosthetic Arm (HAL Archive)
                        </a>
                    </p>
                </div>

            </div>
        </div>
    </body>
</html> -->

<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Adaptive Training for Prosthetic Control</title>
    <link rel="stylesheet" href="../assets/css/style.css" />
  </head>
  <body>
    <header class="site-header">
      <div class="wrap header-inner">
        <nav class="site-nav">
          <a href="./">Home</a>
          <a href="../about.html">About</a>
          <a href="../projects.html">Projects</a>
          <a href="../contact.html">Contact</a>
        </nav>
      </div>
    </header>

    <div class="container">
      <!-- HERO -->
      <div class="hero">
        <h1>Adaptive Training for Prosthetic Control</h1>
        <p class="tagline">
          Using data to personalize motor learning and improve user outcomes
        </p>
        <div class="hero-links">
          <a
            href="https://github.com/vayneeS/prosthesis-strategies-with-ml"
            target="_blank"
            >View Code</a
          >
        </div>
      </div>

      <div class="content">
        <!-- PROJECT SUMMARY -->
        <div class="story-section" id="overview">
          <h2>The Problem</h2>
          <p>
            Prosthetic arm users struggle to maintain reliable control of their
            devices. Training strategies directly impact how quickly users learn
            to translate muscle signals (EMG) into accurate prosthetic
            movementsâ€”but most systems use random, one-size-fits-all approaches
            that ignore individual learning needs.
          </p>
          <p>
            <strong>Question:</strong> Can an adaptive training strategyâ€”one
            that personalizes gesture selection based on real-time performance
            help users learn faster and achieve better long-term control?
          </p>
        </div>

        <!-- APPROACH -->
        <div class="story-section" id="approach">
          <h2>Approach</h2>
          <p>
            To test the adaptive training strategy, I did a user study comparing
            it to two other training strategies across 50+ participants:
          </p>

          <div class="data-list">
            <ul>
              <li>
                <strong>Random:</strong> Gestures presented in random order
                (baseline)
              </li>
              <li>
                <strong>User-Choice:</strong> Users select gestures based on
                perceived difficulty
              </li>
              <li>
                <strong>Adaptive:</strong> Adaptive strategy that selects
                gestures based on classifier performance, focusing practice
                where it matters most
              </li>
            </ul>
          </div>

          <figure>
            <img
              src="../images/experiment.png"
              alt="Myo armband EMG data collection setup"
              class="responsive-img"
            />
            <figcaption>
              Participants wore a Myo armband and performed gestures following
              one of three training strategies.
            </figcaption>
          </figure>
        </div>

        <div class="story-section" id="data-pipeline">
          <h2>Data Pipeline Design</h2>
          <p>
            <strong>The Challenge:</strong> Raw EMG signals from wearable
            sensors are produced from muscle contractions, which can change 
            with sensor placement or user fatigue, confusing classification models.
          </p>
            <p>
            I designed and implemented a data pipeline to turn raw, noisy sensor signals into reliable, actionable data. 
            The first step was signal cleaning: removing electrical interference while preserving meaningful muscle activity. 
            Next, I standardized the 8 sensor channels so each one contributed equallyâ€”similar to balancing audio inputs so no single signal dominates the output. 
            Finally, I aggregated high-frequency predictions (every 200ms) into one performance score per trial, enabling consistent tracking across 120 training rounds per user.
            </p>

            <p>
            <strong>Why it matters:</strong> Without proper preprocessing, models risk learning noise instead of real movement patterns. 
            This pipeline improved data quality, ensured fair comparisons across 50+ users with different physiologies and sensor placements, 
            and made performance metrics robust enough for large-scale analysis.
            </p>
        </div>

        <!-- 2. MACHINE LEARNING -->
        <div class="story-section" id="machine-learning">
          <h2>Machine Learning: How the System Recognizes Gestures</h2>
            <p>
            <strong>The Model:</strong> I implemented Linear Discriminant Analysis (LDA) to classify gestures from sensor data. 
            In simple terms, LDA identifies the clearest boundaries between gesture categories by maximizing the separation 
            between them. Rather than memorizing individual samples, it learns the core signal patterns that distinguish one gesture from another.
            </p>

            <p>
            <strong>Why this approach?</strong> The dataset was relatively small (120 training rounds) and the signals were inherently noisy. 
            LDA is well-suited for this context because it performs efficiently with limited data and low-dimensional inputs 
            (8 sensor features per gesture). Its simplicity reduces the risk of overfitting and keeps the model stable and interpretable.
            </p>

            <p>
            <strong>The Adaptive Layer:</strong> After each training round, the system analyzes classification errors to identify 
            which gesture pairs are most frequently confused. These gestures are then prioritized in the next round. 
            Instead of random repetition, the training loop focuses on the userâ€™s specific weak points, making the system both 
            data-driven and performance-optimized.
            </p>
        </div>

        <!-- 3. STATISTICAL ANALYSIS -->
        <div class="story-section" id="statistical-analysis">
        <h2>Statistical Analysis: Validating Impact</h2>
        
        <p>
            <strong>The Objective:</strong> Observing different learning curves wasnâ€™t enough. 
            We need to validate that the performance gaps between training strategies were statistically meaningfulâ€”not random variation.
        </p>
        
        <p>
            <strong>Learning Speed:</strong> I quantified each participantâ€™s improvement rate over time and compared groups using ANOVA. 
            The analysis showed that users trained with the adaptive training strategy improved significantly faster than the other groups. 
            The likelihood that this difference occurred by chance was less than 0.1%, indicating a strong and reliable effect.
        </p>
        
        <p>
            <strong>Skill Transfer:</strong> I also evaluated whether participants could apply what they learned to reproduce gestures which would likely be recognised with the trained classifier â€”an indicator of true skill acquisition rather than memorization. 
            Because the performance scores were not normally distributed, I used a non-parametric test (Kruskal-Wallis). 
            The adaptive group again outperformed the user-choice group, with only a 3% probability that this result was due to chance (p = 0.03).
        </p>

        <p>
            <strong>Effect Size:</strong> Beyond statistical significance, itâ€™s important to measure 
            how large the difference actually is. Effect size quantifies the magnitude of impactâ€” 
            for example, using metrics such as Î·Â² (eta squared) for ANOVA or Cohenâ€™s d for pairwise 
            comparisons. 
            For clarity and readability, detailed effect size values are not reported here, 
            but they were computed during the analysis to ensure the results were not only 
            statistically significant but also practically meaningful.
        </p>
        </div>

        <!-- RESULTS -->
        <h2>Key Results & visualizations</h2>

        <h3>1. Adaptive training reduces time-to-competency</h3>
        <figure>
        <img
            src="../images/Learning_rates_by_strategy.png"
            alt="Learning rates by strategy"
            class="responsive-img"
        />
        <figcaption>
            Users exposed to adaptive gesture selection improved significantly faster 
            than those using random or self-directed practice. Statistical validation 
             confirms this is a robust effect, not random variation. 
            In practical terms: the adaptive system increases learning speed.
        </figcaption>
        </figure>

        <h3>2. Faster learning â€” without sacrificing final performance</h3>
        <figure>
        <img
            src="../images/accuracy_across_trials_by_strategy.png"
            alt="Accuracy across trials"
            class="responsive-img"
        />
        <figcaption>
            All groups reached similar peak accuracy by the end of training. 
            The difference lies in speed: users trained with the adaptive strategy achieved proficiency earlier. 
            This translates into reduced training time while maintaining the same 
            performance ceiling â€” an efficiency gain with no trade-off in quality.
        </figcaption>
        </figure>

        <h3>3. Stronger skill transfer and system understanding</h3>
        <figure>
        <img
            src="../images/TPR.png"
            alt="Test accuracy"
            class="responsive-img"
        />
        <figcaption>
            When tested on new movement sequences, users trained using the adaptive strategy performed significantly 
            better (p = 0.03) than users of the user-choice strategy. This indicates deeper skill acquisition and better generalization, 
            rather than short-term memorization. 
        </figcaption>
        </figure>

        <!-- INSIGHTS -->
        <div class="story-section" id="insights">
          <h2>Key Insights</h2>

          <div class="finding-card">
            <h4>ðŸš€ Faster onboarding</h4>
            <p>
              Adaptive training reduces time-to-competency by focusing practice
              on gestures the classifier struggles with. This creates steeper
              learning curves without requiring more total practice time.
            </p>
            <p>
              <strong>Impact:</strong> Shorter training sessions, lower user
              frustration, faster clinical deployment
            </p>
          </div>

          <div class="finding-card">
            <h4>ðŸ§  Better user understanding</h4>
            <p>
              Users trained adaptively developed stronger mental modelsâ€”they
              understood why the system responded the way it did, not just how
              to trigger specific actions.
            </p>
            <p>
              <strong>Impact:</strong> Improved long-term adherence, reduced
              support load, higher user confidence
            </p>
          </div>

          <div class="finding-card">
            <h4>ðŸŽ¯ Practical implementation</h4>
            <p>
              The adaptive strategy is simple: select gestures with lowest
              classifier separability.
            </p>
            <p>
              <strong>Impact:</strong> Easy to integrate into existing
              prosthetic training systems
            </p>
          </div>
        </div>

        <!-- RECOMMENDATIONS -->
        <div class="impact-statement" id="recommendations">
          <h3>Recommendations</h3>
          <p>
            <strong>For product teams:</strong> Make adaptive training the
            default onboarding path. Use random/user-choice only as fallback
            options for users who prefer more control.
          </p>
          <p style="margin-top: 15px">
            <strong>For UX designers:</strong> Insist on the logic behind
            gesture selectionâ€”show users why they're practicing specific
            movements. This transparency builds trust and strengthens mental
            models.
          </p>
          <p style="margin-top: 15px">
            <strong>For researchers:</strong> Test this approach beyond
            prosthetics â€”any human-ML system where users learn to generate
            signals (BCIs, rehabilitation tech, surgical training) could benefit
            from adaptive training.
          </p>
        </div>

        <!-- REFERENCE -->
        <div class="story-section" id="repo">
          <p>
            <strong>Reference:</strong>
            <a
              href="https://amu.hal.science/ISIR_ACIDE/hal-04527854v1"
              target="_blank"
            >
              Comparing Teaching Strategies of a Machine Learning-based
              Prosthetic Arm (HAL Archive)
            </a>
          </p>
        </div>
      </div>
    </div>
  </body>
</html>
