<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Optimizing Training Strategies for EMG-Controlled Prostheses</title>
        <link rel="stylesheet" href="../assets/css/style.css">
    </head>
    <body>
        <header class="site-header">
            <div class="wrap header-inner">
                <!-- keep header layout consistent with index: site title hidden in header to avoid duplication with hero -->
                <!-- <h2 class="site-title"><a href="./">Vaynee Sungeelee</a></h2> -->
                <nav class="site-nav">
                    <a href="./">Home</a>
                    <a href="../about.html">About</a>
                    <a href="../projects.html">Projects</a>
                    <a href="../contact.html">Contact</a>
                </nav>
            </div>
        </header>

        <div class="container">
            <!-- 1. HERO SECTION -->
            <div class="hero">
                <h1>Optimizing Training Strategies for EMG-Controlled Prostheses</h1>
                <p class="tagline">A PhD project turned into a data analysis case study.</p>
                <div class="hero-links">
                    <a href="https://github.com/vayneeS/prosthesis-strategies-with-ml" target="_blank">View Code on GitHub</a>
                </div>
            </div>

            <div class="content">
                <!-- 2. PROJECT OVERVIEW -->
                <div class="story-section" id="overview">
                    <h2>Project Overview</h2>
                    <p>
                        One of the problems faced by prosthesis users is the lack of control of their device over time. Controlling an upper-limb prosthesis means learning how muscle signals (EMG) are translated into
                        actions by a machine-learning classifier. Training strategies directly affect how quickly and how
                        well users acquire this control.
                    </p>
                    <p>
                        In this project, I analyzed EMG data from users performing gesture training under different strategies
                        to answer a simple product question: <strong>how should we structure training so that people learn
                        faster and control the device more reliably?</strong>. The strategy I developed is adaptive, which means
                        that it tailors the training sequence based on each user's performance.
                    </p>
                    <p>This case study reframes my PhD work as an end-to-end data analysis project, showcasing how I:</p>
                    <ul>
                        <li>Work with noisy biosignals</li>
                        <li>Define clear metrics for learning</li>
                        <li>Compare training strategies</li>
                        <li>Extract product-ready insights and recommendations</li>
                    </ul>
                </div>

                <div class="story-section" id="skills">
                    <h2>This Project Demonstrates</h2>
                    <ul>
                        <li>Working with <strong>noisy time-series biosignals</strong> and applying appropriate smoothing</li>
                        <li>Designing <strong>interpretable metrics</strong> for learning and user understanding</li>
                        <li>Building a <strong>structured analysis pipeline</strong> from raw data to visual summaries</li>
                        <li>Comparing training strategies using <strong>clear visual and statistical evidence</strong></li>
                        <li>Translating complex experimental results into <strong>product-ready insights</strong></li>
                        <li>Thinking in terms of <strong>user experience, onboarding, and long-term engagement</strong></li>
                        <li>Communicating findings in a way that is accessible to <strong>data leads, clinicians, and product managers</strong></li>
                    </ul>
                </div>

                <!-- 3. BUSINESS QUESTIONS -->
                <div class="story-section" id="business-questions">
                    <h2>Business Questions</h2>
                    <p>
                        Reframed from the original research aims, the analysis focused on three core business questions:
                    </p>

                    <div class="highlight-box">
                        <h4>2. Does an adaptive training strategy improve the classifier's performance during training?</h4>
                        <p>
                            I treat trial-level classification accuracy as a proxy for quality of EMG control and skill
                            acquisition, and compare it across strategies.
                        </p>
                    </div>

                    <div class="highlight-box">
                        <h4>1. Can adaptive training help users reach accurate prosthesis control faster?</h4>
                        <p>
                            Here, I compare how quickly users improve classification accuracy under different training
                            strategies. This reflects learning speed and onboarding efficiency.
                        </p>
                    </div>

                    <div class="highlight-box">
                        <h4>3. Does adaptive training strengthen the user's mental model of how the prosthesis interprets their movements?</h4>
                        <p>
                            I evaluate user performance on post-training functional tests to assess whether they have a
                            more accurate intuition of how the ML model responds to their gestures.
                        </p>
                    </div>

                    <p>
                        These questions could translate into product concerns such as <strong>reducing time to competency,
                        improving user experience, and increasing long-term confidence in the device</strong>.
                    </p>
                </div>

                <!-- 4. DATASET & METRICS -->
                <div class="story-section" id="data-metrics">
                    <h2>Data collection and Key Metrics</h2>
                    <p>
                        The dataset comes from EMG-based training sessions which I led, where users practiced hand and wrist gestures
                        with different training strategies. The goal was to see how these strategies affected learning and control.
                        I used a Myo armband to collect multichannel EMG data as users trained a machine-learning classifier to recognize their gestures.
                        The Myo device streams EMG signals from 8 sensors placed around the forearm, capturing muscle activity during gesture attempts.
                    </p>

                    <figure>
                        <img src="../images/experiment.png" alt="Myo armband setup for EMG data collection" class="responsive-img">
                        <figcaption>
                            The Myo armband is placed on the user's forearm for EMG data collection during prosthesis training sessions.
                            Users performed a series of hand and wrist gestures while the device recorded multichannel EMG signals.
                            A robotic prosthesis provided real-time feedback based on the classifier's predictions.
                        </figcaption>
                    </figure>

                    <h2>Data Overview</h2>
                    <table class="portfolio-table">
                        <thead>
                            <tr>
                                <th>Column</th>
                                <th>Type</th>
                                <th>Description</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>pid</strong></td>
                                <td>Integer</td>
                                <td>Participant ID. Identifies which user the EMG sample comes from.</td>
                            </tr>
                            <tr>
                                <td><strong>cond</strong></td>
                                <td>String</td>
                                <td>Training condition used during data collection.</td>
                            </tr>
                            <tr>
                                <td><strong>trial</strong></td>
                                <td>Integer</td>
                                <td>Order index of the movement during training.</td>
                            </tr>
                            <tr>
                                <td><strong>x</strong></td>
                                <td>List of floats</td>
                                <td>RMS features extracted from the EMG window (one per channel).</td>
                            </tr>
                            <tr>
                                <td><strong>y</strong></td>
                                <td>String</td>
                                <td>Gesture label corresponding to the window.</td>
                            </tr>
                        </tbody>
                    </table>

                    <div class="data-list">
                        <h4>Data Sources:</h4>
                        <ul>
                            <li>Multichannel EMG signals from a Myo armband (8 channels)</li>
                            <li>120 training trials per participant</li>
                            <li>3 prosthesis training strategies:
                                <ul>
                                    <li><strong>Random Curriculum (RC).</strong> The gestures are presented in a random order without any specific selection criteria.</li>
                                    <li><strong>User-Choice Curriculum (UCC).</strong> The user selects gestures based on their preference or perceived difficulty.</li>
                                    <li><strong>Gesture Separability Curriculum (GSC).</strong> This is the adaptive curriculum, which selects the most informative gestures based on separability metrics.</li>
                                </ul>
                            </li>
                        </ul>
                    </div>

                    <div class="data-list">
                        <h4>Key Metrics:</h4>
                        <ul>
                            <li><strong>Learning speed</strong>
                                <ul>
                                    <li>Evolution of classification accuracy over 120 trials.
                                        Accuracy corresponds to the proportion of correctly classified signal windows within each trial.
                                        After the training phase, a post-test was performed to generate an independent test set, which was then used to evaluate model accuracy throughout the training process.</li>
                                    <li>Learning rate per strategy.
                                        Learning curves often follow a power-law, expressed as <span><strong>log(Performance) = log(k) + Î± log(Number of trials)</strong></span>.
                                        Linear regression on learning data transforms the learning function into a straight line, which can be analyzed. The slope gives the learning rate; a steeper positive slope â†’ faster improvement in performance.</li>
                                </ul>
                            </li>
                            <li><strong>User understanding / mental model</strong>
                                <ul>
                                    <li>Accuracy obtained on post-training functional tests</li>
                                    <li>Reflects how well users understand how the prosthesis interprets their movements</li>
                                </ul>
                            </li>
                        </ul>
                    </div>

                    <p>
                        These metrics provide an analytical link between the accuracy of the signal classification, user learning, and
                        product experience.
                    </p>
                </div>

                <!-- 5. ANALYSIS & ML PIPELINE -->
                <div class="story-section">
                    <p>
                        My analysis and machine learning pipeline relied on a set of core Python libraries:
                    </p>
                    <ul class="tech-list">
                        <li>
                            <strong>Data preprocessing:</strong>
                            <span class="tech-name">NumPy</span> and
                            <span class="tech-name">pandas</span> for numerical operations and structured data handling.
                        </li>
                        <li>
                            <strong>Statistical analysis:</strong>
                            <span class="tech-name">SciPy</span> for basic statistics and
                            <span class="tech-name">statsmodels</span> for more advanced tests such as ANOVAs.
                        </li>
                        <li>
                            <strong>Machine learning:</strong>
                            <span class="tech-name">scikit-learn</span> to build a classification pipeline using
                            <em>StandardScaler</em> and <em>LinearDiscriminantAnalysis</em> for predicting EMG-based movement classes.
                            <p>
                                LDA works well for prosthesis classification because it is fast, interpretable, and performs reliably even with noisy or limited EMG data.
                                Its strength lies in how it maximizes class separability: it finds a projection where signals from different movements are pushed as far apart as possible while each movement remains internally compact.
                                This makes LDA both efficient and robust for real-time control systems. The adaptive training strategy (GSC) specifically leverages this property by selecting gestures that are less separable, thereby focusing user practice on the most challenging distinctions.
                            </p>
                        </li>
                        <li>
                            <strong>Performance evaluation:</strong>
                            confusion matrices to inspect per-class accuracy and understand how the model performs across gestures.
                        </li>
                        <li>
                            <strong>Visualization:</strong>
                            <span class="tech-name">Matplotlib</span> and
                            <span class="tech-name">Seaborn</span> to create learning curves and summary bar plots.
                        </li>
                    </ul>
                </div>

                <!-- 5. METHODOLOGY -->
                <div class="methodology" id="methodology">
                    <h3>Methodology: From Noisy EMG to Learning Curves</h3>
                    <p>
                        Even with a relatively small dataset, EMG signals are inherently noisy. I applied focused,
                        realistic preprocessing steps:
                    </p>

                    <h4>Root Mean Square (RMS) smoothing of EMG channels</h4>
                    <ul>
                        <li>Applied Root Mean Square (RMS) smoothing to each channel</li>
                        <li>Reduced high-frequency noise and stabilized signal envelopes</li>
                        <li>Prepared the data for robust classification and feature extraction</li>
                    </ul>

                    <figure>
                        <img src="../images/rms.png" alt="Root Mean Square (RMS) smoothing snippet" class="responsive-img">
                        <figcaption>
                            Root Mean Square (RMS) smoothing.
                        </figcaption>
                    </figure>

                    <h4>Participant-level outlier removal</h4>
                    <ul>
                        <li>Identified participants with extreme average accuracy values (e.g. >3 standard deviations from the group)</li>
                        <li>Removed these outliers to avoid distorted group-level trends</li>
                        <li><strong>Result:</strong> cleaner learning curves and more reliable comparisons between strategies</li>
                    </ul>

                    <figure>
                        <img src="../images/remove_outliers.png" alt="Remove outliers snippet" class="responsive-img">
                        <figcaption>
                            Example of participant-level outlier removal.
                        </figcaption>
                    </figure>

                    <h4>Trial-level aggregation of accuracy</h4>
                    <ul>
                        <li>Aggregated window-level classifier predictions into a single accuracy score per trial</li>
                        <li>Enabled consistent tracking of performance for each user across 120 trials</li>
                    </ul>

                    <p style="margin-top: 20px;"><strong>The analysis pipeline then followed this structure:</strong></p>
                    <ol>
                        <li>Apply RMS smoothing to EMG streams</li>
                        <li>Extract features- RMS is itself an amplitude-based feature, normalize using the StandardScaler, and classify EMG windows</li>
                        <li>Aggregate predictions into trial-level accuracy</li>
                        <li>Plot learning curves for each strategy</li>
                        <li>Compute learning rate of the classifier</li>
                        <li>Compare post-training functional outcomes to assess mental models</li>
                    </ol>
                </div>

                <!-- 6. VISUAL ANALYSIS -->
                <div class="story-section" id="visual-analysis">
                    <h2>Visual Analysis</h2>

                    <h3>Learning Curves</h3>
                    <figure>
                        <img src="../images/accuracy_across_trials_by_strategy.png" alt="Learning curves showing classification accuracy over 120 trials" class="responsive-img">
                        <figcaption>
                            Learning curves showing classification accuracy over 120 trials for each training strategy.
                            The adaptive strategy displays a slower early increase and seems to reach a plateau near the end of training.
                            The differences in final accuracy across strategies are not significant, meaning that there is no evidence that they are similar.
                        </figcaption>
                    </figure>

                    <h3>Learning rates</h3>
                    <figure>
                        <img src="../images/Learning_rates_by_strategy.png" alt="Learning rates across strategies" class="responsive-img">
                        <figcaption>
                            Learning rates derived from log-log transformed accuracy data. The adaptive strategy (GSC)
                            shows a significantly higher learning rate, indicating that users improve their control
                            skills more rapidly compared to other strategies. Absolute values of learning rates are shown on the bars.
                        </figcaption>
                    </figure>

                    <h3>Functional Performance / Mental Model</h3>
                    <figure>
                        <img src="../images/TPR_comparison.png" alt="Post-training functional accuracy comparison" class="responsive-img">
                        <figcaption>
                            Post-training functional accuracy for each strategy. Users trained with the adaptive strategy
                            perform better on test tasks that require anticipating how the classifier responds to their gestures,
                            reflecting a stronger mental model of the system.
                        </figcaption>
                    </figure>
                </div>

                <!-- 7. INSIGHTS & RECOMMENDATIONS -->
                <div class="story-section" id="insights">
                    <h2>Insights & Recommendations</h2>

                    <div class="finding-card">
                        <h4>ðŸš€ Insight 1 â€“ Adaptive training accelerates learning</h4>
                        <p>
                            <strong>Insight:</strong> Users trained with the adaptive strategy (GSC) improved their classification
                            accuracy significantly faster (x% increase, p < 0.05, effect-size = ) than other groups. Learning curves
                            show steeper improvement and earlier stabilization, indicating more efficient learning dynamics.
                        </p>
                        <p>
                            <strong>Recommendation:</strong> Integrate performance-based adaptive curriculum into the prosthesis
                            training workflow. Automatically selecting the next gesture based on user performance can shorten
                            onboarding time, reduce trial-and-error frustration, and make early sessions more rewarding for
                            new users.
                        </p>
                    </div>

                    <div class="finding-card">
                        <h4>ðŸŽ¯ Insight 2 â€“ Adaptive training leads to stronger gains in performance</h4>
                        <p>
                            <strong>Insight:</strong> By the end of training, users trained with the adaptive strategy (GSC) achieved both a
                            larger increase in accuracy (x% increase, p < 0.05, effect-size = ) compared to other groups. With final accuracies which converge for all strategies,
                            adaptive training appears to help users learn faster. This could lead to more reliable control in the long run.
                        </p>
                        <p>
                            <strong>Recommendation:</strong> Make adaptive training the default path for new prosthesis users,
                            while keeping random or fixed curricula only as backup options. This can reduce the number of
                            sessions required to reach clinical competency and lower the support load for clinicians or
                            product specialists.
                        </p>
                    </div>

                    <div class="finding-card">
                        <h4>ðŸ§  Insight 3 â€“ Adaptive training strengthens user mental models</h4>
                        <p>
                            <strong>Insight:</strong> Users trained with the adaptive strategy performed better (x% , p < 0.05, effect-size = ) on post-training
                            functional tests, indicating a deeper understanding or intuition of how the prosthesis interprets their muscle
                            signals.
                        </p>
                        <p>
                            <strong>Recommendation:</strong> Strengthen the intuition by combining adaptive training with simple in-app feedback that explains
                            why specific gestures are selected or repeated. Surfacing this logic helps users form accurate
                            expectations of the device, improving long-term trust, adherence, and overall user satisfaction.
                        </p>
                    </div>
                </div>

                <!-- 8. IMPACT STATEMENT -->
                <div class="impact-statement" id="impact">
                    <h3>Next Steps</h3>
                    <p>
                        This analysis shows that a relatively simple adaptive strategy, combined with basic signal preprocessing
                        (RMS smoothing) and targeted outlier removal, can significantly improve how users learn to control a
                        machine-learning-driven device.
                    </p>
                    <p style="margin-top: 15px;">
                        For product teams working on prosthetics, rehabilitation tools, gaming, or any human-in-the-loop ML
                        system, <strong>structuring training around user performance is a powerful lever
                        for better onboarding, stronger skills, and more confident long-term use</strong>.
                    </p>
                </div>

                <!-- 9. SKILLS DEMONSTRATED -->

                <!-- 10. REPOSITORY LINK -->
                <!-- <div class="story-section" id="repo">
                    <h2>Code and Reproducibility</h2>
                    <p>
                        The full code, preprocessing scripts, and analysis notebooks for this project are available here:
                    </p>
                    <a href="https://github.com/vayneeS/prosthesis-strategies-with-ml" target="_blank" class="repo-link">
                        ðŸ“‚ View GitHub Repository
                    </a>
                </div> -->
                <div class="story-section" id="repo">
                    <p>
                        Reference:
                        <a href="https://amu.hal.science/ISIR_ACIDE/hal-04527854v1" target="_blank">
                            Comparing Teaching Strategies of a Machine Learning-based Prosthetic Arm (HAL Archive)
                        </a>
                    </p>
                </div>

            </div>
        </div>
    </body>
</html>